{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xlmr+pho+news.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e72a4de4036d47deac245c971bf4da91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7427f0b12e5b4d1087c20cb7a68b810e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bdec64ec546a42a19f361645f96910b0","IPY_MODEL_3449855977ea472f88e9fcf526571eaa"]}},"7427f0b12e5b4d1087c20cb7a68b810e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdec64ec546a42a19f361645f96910b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a1268eee30b41fdb5f964e04ed0425e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":551,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":551,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a7041109fb44ed3977d9d274301af25"}},"3449855977ea472f88e9fcf526571eaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d08169502adf488e9edccef4136ccc68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 551/551 [00:00&lt;00:00, 1.22kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9e40c4b059144a3a082d461f90b2686"}},"2a1268eee30b41fdb5f964e04ed0425e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7a7041109fb44ed3977d9d274301af25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d08169502adf488e9edccef4136ccc68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d9e40c4b059144a3a082d461f90b2686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffc2513521444ff597be1d83db47a157":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_319a59cebedb4591aff092427256a23d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_939b8a26316849aa817b91fd176dc953","IPY_MODEL_40fd9264f63e47b1939d26a0f8d9512f"]}},"319a59cebedb4591aff092427256a23d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"939b8a26316849aa817b91fd176dc953":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a9608fa9ab894f6dbbb67ee3bbe17abe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":537300317,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":537300317,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7bd378c74ca4ce6b89db06baa905548"}},"40fd9264f63e47b1939d26a0f8d9512f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a91d007c4b994df088033918a9d883cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 537M/537M [00:15&lt;00:00, 33.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92b56e4c235e4785818f8d8bed4c43d6"}},"a9608fa9ab894f6dbbb67ee3bbe17abe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7bd378c74ca4ce6b89db06baa905548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a91d007c4b994df088033918a9d883cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"92b56e4c235e4785818f8d8bed4c43d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc4b550598aa4c7ebc994a85f35b4bac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa8d7454eb584bedaf0214943b24a5c5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ab31c4442bd34ac0a41752388d754682","IPY_MODEL_cf93d2a90cb2406fb1f239704214564c"]}},"aa8d7454eb584bedaf0214943b24a5c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab31c4442bd34ac0a41752388d754682":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cce5550b217b4d358dbcabe76e348181","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":411325,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":411325,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae3d6785a03b44e485dbea939eef5fab"}},"cf93d2a90cb2406fb1f239704214564c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67453085ed6648c6b6c675ee512f1913","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 411k/411k [00:00&lt;00:00, 540kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89aecfba82054c58b8cdcc66c552490b"}},"cce5550b217b4d358dbcabe76e348181":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae3d6785a03b44e485dbea939eef5fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67453085ed6648c6b6c675ee512f1913":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89aecfba82054c58b8cdcc66c552490b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42b4007c5ec24dac9b2778dd2a374b96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a19eab916fda4e248b487e72019077ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3051bfdde7bf4254af534e21f79b24ef","IPY_MODEL_5b1951768b5b40749e2395126ddc1f1d"]}},"a19eab916fda4e248b487e72019077ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3051bfdde7bf4254af534e21f79b24ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea56dd9a45084793bf238a1a11c17ea5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef886ae70c4b484994ebbd0e9a57ab01"}},"5b1951768b5b40749e2395126ddc1f1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7f3b15155faf4454ace705aa0e16452e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 136B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a2b4c981e5e46b197d87a3eb46cab02"}},"ea56dd9a45084793bf238a1a11c17ea5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef886ae70c4b484994ebbd0e9a57ab01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f3b15155faf4454ace705aa0e16452e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a2b4c981e5e46b197d87a3eb46cab02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtJni3x9O6sQ","executionInfo":{"status":"ok","timestamp":1619282181618,"user_tz":-420,"elapsed":8086,"user":{"displayName":"Vĩ Trần Tuấn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjc8eSDsubZaR8W3AcsFrZjBWP1jmcrbcsXAz_4GQ=s64","userId":"12285368666031482492"}},"outputId":"07ed0330-146b-42b0-97cb-d752b1c44f19"},"source":["!cd \"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis\"\n","!pip install transformers\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 22.8MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 35.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jPDw66hbPKuZ"},"source":["import torch\n","import pandas as pd\n","import numpy as np\n","\n","# Thu vien transformer cho Classification\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification\n","\n","# Xu ly label\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Metric danh gia \n","from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","\n","# Ve do thi\n","import seaborn as sn\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCLD7ofHPLDh"},"source":["# Xay dung data de fit vao mo hinh \n","class BuildDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nS0nrHUzPNLR","executionInfo":{"status":"ok","timestamp":1619282189822,"user_tz":-420,"elapsed":16275,"user":{"displayName":"Vĩ Trần Tuấn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjc8eSDsubZaR8W3AcsFrZjBWP1jmcrbcsXAz_4GQ=s64","userId":"12285368666031482492"}},"outputId":"6dfefeca-9874-454e-87c2-21d5a26fdb43"},"source":["# Doc du lieu\n","!cd \"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis\"\n","train = pd.read_excel(\"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis/dataset/train_nor_811.xlsx\", index_col=False)\n","dev = pd.read_excel(\"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis/dataset/valid_nor_811.xlsx\", index_col=False)\n","test = pd.read_excel(\"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis/dataset/test_nor_811.xlsx\", index_col=False)\n","\n","X_train = train['Sentence']\n","y_train = train['Emotion'].values\n","\n","X_dev = dev['Sentence']\n","y_dev = dev['Emotion'].values\n","\n","X_test = test['Sentence']\n","y_test = test['Emotion'].values\n","\n","print(len(train))\n","print(len(dev))\n","print(len(test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5548\n","686\n","693\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316,"referenced_widgets":["e72a4de4036d47deac245c971bf4da91","7427f0b12e5b4d1087c20cb7a68b810e","bdec64ec546a42a19f361645f96910b0","3449855977ea472f88e9fcf526571eaa","2a1268eee30b41fdb5f964e04ed0425e","7a7041109fb44ed3977d9d274301af25","d08169502adf488e9edccef4136ccc68","d9e40c4b059144a3a082d461f90b2686","ffc2513521444ff597be1d83db47a157","319a59cebedb4591aff092427256a23d","939b8a26316849aa817b91fd176dc953","40fd9264f63e47b1939d26a0f8d9512f","a9608fa9ab894f6dbbb67ee3bbe17abe","f7bd378c74ca4ce6b89db06baa905548","a91d007c4b994df088033918a9d883cd","92b56e4c235e4785818f8d8bed4c43d6","dc4b550598aa4c7ebc994a85f35b4bac","aa8d7454eb584bedaf0214943b24a5c5","ab31c4442bd34ac0a41752388d754682","cf93d2a90cb2406fb1f239704214564c","cce5550b217b4d358dbcabe76e348181","ae3d6785a03b44e485dbea939eef5fab","67453085ed6648c6b6c675ee512f1913","89aecfba82054c58b8cdcc66c552490b","42b4007c5ec24dac9b2778dd2a374b96","a19eab916fda4e248b487e72019077ef","3051bfdde7bf4254af534e21f79b24ef","5b1951768b5b40749e2395126ddc1f1d","ea56dd9a45084793bf238a1a11c17ea5","ef886ae70c4b484994ebbd0e9a57ab01","7f3b15155faf4454ace705aa0e16452e","7a2b4c981e5e46b197d87a3eb46cab02"]},"id":"vu0LBFGwPLF5","executionInfo":{"status":"ok","timestamp":1619282211851,"user_tz":-420,"elapsed":38295,"user":{"displayName":"Vĩ Trần Tuấn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjc8eSDsubZaR8W3AcsFrZjBWP1jmcrbcsXAz_4GQ=s64","userId":"12285368666031482492"}},"outputId":"014a1218-a6d4-4540-c57f-40caed0b1fc5"},"source":["import torch\n","from transformers import BertTokenizer,BertModel\n","from transformers import AutoModel, AutoTokenizer\n","\n","# Define the model name in transformers repository\n","model = AutoModelForSequenceClassification.from_pretrained(\"NlpHUST/vibert4news-base-cased\", num_labels = 7)\n","tokenizer = BertTokenizer.from_pretrained(\"NlpHUST/vibert4news-base-cased\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e72a4de4036d47deac245c971bf4da91","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=551.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffc2513521444ff597be1d83db47a157","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=537300317.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at NlpHUST/vibert4news-base-cased were not used when initializing IBertForSequenceClassification: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing IBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing IBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of IBertForSequenceClassification were not initialized from the model checkpoint at NlpHUST/vibert4news-base-cased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.word_embeddings.weight_scaling_factor', 'embeddings.word_embeddings.weight_integer', 'embeddings.token_type_embeddings.weight', 'embeddings.token_type_embeddings.weight_scaling_factor', 'embeddings.token_type_embeddings.weight_integer', 'embeddings.position_embeddings.weight', 'embeddings.position_embeddings.weight_scaling_factor', 'embeddings.position_embeddings.weight_integer', 'embeddings.embeddings_act1.x_min', 'embeddings.embeddings_act1.x_max', 'embeddings.embeddings_act1.act_scaling_factor', 'embeddings.embeddings_act2.x_min', 'embeddings.embeddings_act2.x_max', 'embeddings.embeddings_act2.act_scaling_factor', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.shift', 'embeddings.LayerNorm.activation.x_min', 'embeddings.LayerNorm.activation.x_max', 'embeddings.LayerNorm.activation.act_scaling_factor', 'embeddings.output_activation.x_min', 'embeddings.output_activation.x_max', 'embeddings.output_activation.act_scaling_factor', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight_integer', 'encoder.layer.0.attention.self.query.fc_scaling_factor', 'encoder.layer.0.attention.self.query.bias_integer', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight_integer', 'encoder.layer.0.attention.self.key.fc_scaling_factor', 'encoder.layer.0.attention.self.key.bias_integer', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight_integer', 'encoder.layer.0.attention.self.value.fc_scaling_factor', 'encoder.layer.0.attention.self.value.bias_integer', 'encoder.layer.0.attention.self.query_activation.x_min', 'encoder.layer.0.attention.self.query_activation.x_max', 'encoder.layer.0.attention.self.query_activation.act_scaling_factor', 'encoder.layer.0.attention.self.key_activation.x_min', 'encoder.layer.0.attention.self.key_activation.x_max', 'encoder.layer.0.attention.self.key_activation.act_scaling_factor', 'encoder.layer.0.attention.self.value_activation.x_min', 'encoder.layer.0.attention.self.value_activation.x_max', 'encoder.layer.0.attention.self.value_activation.act_scaling_factor', 'encoder.layer.0.attention.self.output_activation.x_min', 'encoder.layer.0.attention.self.output_activation.x_max', 'encoder.layer.0.attention.self.output_activation.act_scaling_factor', 'encoder.layer.0.attention.self.softmax.act.x_min', 'encoder.layer.0.attention.self.softmax.act.x_max', 'encoder.layer.0.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight_integer', 'encoder.layer.0.attention.output.dense.fc_scaling_factor', 'encoder.layer.0.attention.output.dense.bias_integer', 'encoder.layer.0.attention.output.ln_input_act.x_min', 'encoder.layer.0.attention.output.ln_input_act.x_max', 'encoder.layer.0.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.shift', 'encoder.layer.0.attention.output.LayerNorm.activation.x_min', 'encoder.layer.0.attention.output.LayerNorm.activation.x_max', 'encoder.layer.0.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.0.attention.output.output_activation.x_min', 'encoder.layer.0.attention.output.output_activation.x_max', 'encoder.layer.0.attention.output.output_activation.act_scaling_factor', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight_integer', 'encoder.layer.0.intermediate.dense.fc_scaling_factor', 'encoder.layer.0.intermediate.dense.bias_integer', 'encoder.layer.0.intermediate.output_activation.x_min', 'encoder.layer.0.intermediate.output_activation.x_max', 'encoder.layer.0.intermediate.output_activation.act_scaling_factor', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight_integer', 'encoder.layer.0.output.dense.fc_scaling_factor', 'encoder.layer.0.output.dense.bias_integer', 'encoder.layer.0.output.ln_input_act.x_min', 'encoder.layer.0.output.ln_input_act.x_max', 'encoder.layer.0.output.ln_input_act.act_scaling_factor', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.shift', 'encoder.layer.0.output.LayerNorm.activation.x_min', 'encoder.layer.0.output.LayerNorm.activation.x_max', 'encoder.layer.0.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.0.output.output_activation.x_min', 'encoder.layer.0.output.output_activation.x_max', 'encoder.layer.0.output.output_activation.act_scaling_factor', 'encoder.layer.0.pre_intermediate_act.x_min', 'encoder.layer.0.pre_intermediate_act.x_max', 'encoder.layer.0.pre_intermediate_act.act_scaling_factor', 'encoder.layer.0.pre_output_act.x_min', 'encoder.layer.0.pre_output_act.x_max', 'encoder.layer.0.pre_output_act.act_scaling_factor', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight_integer', 'encoder.layer.1.attention.self.query.fc_scaling_factor', 'encoder.layer.1.attention.self.query.bias_integer', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight_integer', 'encoder.layer.1.attention.self.key.fc_scaling_factor', 'encoder.layer.1.attention.self.key.bias_integer', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight_integer', 'encoder.layer.1.attention.self.value.fc_scaling_factor', 'encoder.layer.1.attention.self.value.bias_integer', 'encoder.layer.1.attention.self.query_activation.x_min', 'encoder.layer.1.attention.self.query_activation.x_max', 'encoder.layer.1.attention.self.query_activation.act_scaling_factor', 'encoder.layer.1.attention.self.key_activation.x_min', 'encoder.layer.1.attention.self.key_activation.x_max', 'encoder.layer.1.attention.self.key_activation.act_scaling_factor', 'encoder.layer.1.attention.self.value_activation.x_min', 'encoder.layer.1.attention.self.value_activation.x_max', 'encoder.layer.1.attention.self.value_activation.act_scaling_factor', 'encoder.layer.1.attention.self.output_activation.x_min', 'encoder.layer.1.attention.self.output_activation.x_max', 'encoder.layer.1.attention.self.output_activation.act_scaling_factor', 'encoder.layer.1.attention.self.softmax.act.x_min', 'encoder.layer.1.attention.self.softmax.act.x_max', 'encoder.layer.1.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight_integer', 'encoder.layer.1.attention.output.dense.fc_scaling_factor', 'encoder.layer.1.attention.output.dense.bias_integer', 'encoder.layer.1.attention.output.ln_input_act.x_min', 'encoder.layer.1.attention.output.ln_input_act.x_max', 'encoder.layer.1.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.shift', 'encoder.layer.1.attention.output.LayerNorm.activation.x_min', 'encoder.layer.1.attention.output.LayerNorm.activation.x_max', 'encoder.layer.1.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.1.attention.output.output_activation.x_min', 'encoder.layer.1.attention.output.output_activation.x_max', 'encoder.layer.1.attention.output.output_activation.act_scaling_factor', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight_integer', 'encoder.layer.1.intermediate.dense.fc_scaling_factor', 'encoder.layer.1.intermediate.dense.bias_integer', 'encoder.layer.1.intermediate.output_activation.x_min', 'encoder.layer.1.intermediate.output_activation.x_max', 'encoder.layer.1.intermediate.output_activation.act_scaling_factor', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight_integer', 'encoder.layer.1.output.dense.fc_scaling_factor', 'encoder.layer.1.output.dense.bias_integer', 'encoder.layer.1.output.ln_input_act.x_min', 'encoder.layer.1.output.ln_input_act.x_max', 'encoder.layer.1.output.ln_input_act.act_scaling_factor', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.shift', 'encoder.layer.1.output.LayerNorm.activation.x_min', 'encoder.layer.1.output.LayerNorm.activation.x_max', 'encoder.layer.1.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.1.output.output_activation.x_min', 'encoder.layer.1.output.output_activation.x_max', 'encoder.layer.1.output.output_activation.act_scaling_factor', 'encoder.layer.1.pre_intermediate_act.x_min', 'encoder.layer.1.pre_intermediate_act.x_max', 'encoder.layer.1.pre_intermediate_act.act_scaling_factor', 'encoder.layer.1.pre_output_act.x_min', 'encoder.layer.1.pre_output_act.x_max', 'encoder.layer.1.pre_output_act.act_scaling_factor', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight_integer', 'encoder.layer.2.attention.self.query.fc_scaling_factor', 'encoder.layer.2.attention.self.query.bias_integer', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight_integer', 'encoder.layer.2.attention.self.key.fc_scaling_factor', 'encoder.layer.2.attention.self.key.bias_integer', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight_integer', 'encoder.layer.2.attention.self.value.fc_scaling_factor', 'encoder.layer.2.attention.self.value.bias_integer', 'encoder.layer.2.attention.self.query_activation.x_min', 'encoder.layer.2.attention.self.query_activation.x_max', 'encoder.layer.2.attention.self.query_activation.act_scaling_factor', 'encoder.layer.2.attention.self.key_activation.x_min', 'encoder.layer.2.attention.self.key_activation.x_max', 'encoder.layer.2.attention.self.key_activation.act_scaling_factor', 'encoder.layer.2.attention.self.value_activation.x_min', 'encoder.layer.2.attention.self.value_activation.x_max', 'encoder.layer.2.attention.self.value_activation.act_scaling_factor', 'encoder.layer.2.attention.self.output_activation.x_min', 'encoder.layer.2.attention.self.output_activation.x_max', 'encoder.layer.2.attention.self.output_activation.act_scaling_factor', 'encoder.layer.2.attention.self.softmax.act.x_min', 'encoder.layer.2.attention.self.softmax.act.x_max', 'encoder.layer.2.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight_integer', 'encoder.layer.2.attention.output.dense.fc_scaling_factor', 'encoder.layer.2.attention.output.dense.bias_integer', 'encoder.layer.2.attention.output.ln_input_act.x_min', 'encoder.layer.2.attention.output.ln_input_act.x_max', 'encoder.layer.2.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.shift', 'encoder.layer.2.attention.output.LayerNorm.activation.x_min', 'encoder.layer.2.attention.output.LayerNorm.activation.x_max', 'encoder.layer.2.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.2.attention.output.output_activation.x_min', 'encoder.layer.2.attention.output.output_activation.x_max', 'encoder.layer.2.attention.output.output_activation.act_scaling_factor', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight_integer', 'encoder.layer.2.intermediate.dense.fc_scaling_factor', 'encoder.layer.2.intermediate.dense.bias_integer', 'encoder.layer.2.intermediate.output_activation.x_min', 'encoder.layer.2.intermediate.output_activation.x_max', 'encoder.layer.2.intermediate.output_activation.act_scaling_factor', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight_integer', 'encoder.layer.2.output.dense.fc_scaling_factor', 'encoder.layer.2.output.dense.bias_integer', 'encoder.layer.2.output.ln_input_act.x_min', 'encoder.layer.2.output.ln_input_act.x_max', 'encoder.layer.2.output.ln_input_act.act_scaling_factor', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.shift', 'encoder.layer.2.output.LayerNorm.activation.x_min', 'encoder.layer.2.output.LayerNorm.activation.x_max', 'encoder.layer.2.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.2.output.output_activation.x_min', 'encoder.layer.2.output.output_activation.x_max', 'encoder.layer.2.output.output_activation.act_scaling_factor', 'encoder.layer.2.pre_intermediate_act.x_min', 'encoder.layer.2.pre_intermediate_act.x_max', 'encoder.layer.2.pre_intermediate_act.act_scaling_factor', 'encoder.layer.2.pre_output_act.x_min', 'encoder.layer.2.pre_output_act.x_max', 'encoder.layer.2.pre_output_act.act_scaling_factor', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight_integer', 'encoder.layer.3.attention.self.query.fc_scaling_factor', 'encoder.layer.3.attention.self.query.bias_integer', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight_integer', 'encoder.layer.3.attention.self.key.fc_scaling_factor', 'encoder.layer.3.attention.self.key.bias_integer', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight_integer', 'encoder.layer.3.attention.self.value.fc_scaling_factor', 'encoder.layer.3.attention.self.value.bias_integer', 'encoder.layer.3.attention.self.query_activation.x_min', 'encoder.layer.3.attention.self.query_activation.x_max', 'encoder.layer.3.attention.self.query_activation.act_scaling_factor', 'encoder.layer.3.attention.self.key_activation.x_min', 'encoder.layer.3.attention.self.key_activation.x_max', 'encoder.layer.3.attention.self.key_activation.act_scaling_factor', 'encoder.layer.3.attention.self.value_activation.x_min', 'encoder.layer.3.attention.self.value_activation.x_max', 'encoder.layer.3.attention.self.value_activation.act_scaling_factor', 'encoder.layer.3.attention.self.output_activation.x_min', 'encoder.layer.3.attention.self.output_activation.x_max', 'encoder.layer.3.attention.self.output_activation.act_scaling_factor', 'encoder.layer.3.attention.self.softmax.act.x_min', 'encoder.layer.3.attention.self.softmax.act.x_max', 'encoder.layer.3.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight_integer', 'encoder.layer.3.attention.output.dense.fc_scaling_factor', 'encoder.layer.3.attention.output.dense.bias_integer', 'encoder.layer.3.attention.output.ln_input_act.x_min', 'encoder.layer.3.attention.output.ln_input_act.x_max', 'encoder.layer.3.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.shift', 'encoder.layer.3.attention.output.LayerNorm.activation.x_min', 'encoder.layer.3.attention.output.LayerNorm.activation.x_max', 'encoder.layer.3.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.3.attention.output.output_activation.x_min', 'encoder.layer.3.attention.output.output_activation.x_max', 'encoder.layer.3.attention.output.output_activation.act_scaling_factor', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight_integer', 'encoder.layer.3.intermediate.dense.fc_scaling_factor', 'encoder.layer.3.intermediate.dense.bias_integer', 'encoder.layer.3.intermediate.output_activation.x_min', 'encoder.layer.3.intermediate.output_activation.x_max', 'encoder.layer.3.intermediate.output_activation.act_scaling_factor', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight_integer', 'encoder.layer.3.output.dense.fc_scaling_factor', 'encoder.layer.3.output.dense.bias_integer', 'encoder.layer.3.output.ln_input_act.x_min', 'encoder.layer.3.output.ln_input_act.x_max', 'encoder.layer.3.output.ln_input_act.act_scaling_factor', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.shift', 'encoder.layer.3.output.LayerNorm.activation.x_min', 'encoder.layer.3.output.LayerNorm.activation.x_max', 'encoder.layer.3.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.3.output.output_activation.x_min', 'encoder.layer.3.output.output_activation.x_max', 'encoder.layer.3.output.output_activation.act_scaling_factor', 'encoder.layer.3.pre_intermediate_act.x_min', 'encoder.layer.3.pre_intermediate_act.x_max', 'encoder.layer.3.pre_intermediate_act.act_scaling_factor', 'encoder.layer.3.pre_output_act.x_min', 'encoder.layer.3.pre_output_act.x_max', 'encoder.layer.3.pre_output_act.act_scaling_factor', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight_integer', 'encoder.layer.4.attention.self.query.fc_scaling_factor', 'encoder.layer.4.attention.self.query.bias_integer', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight_integer', 'encoder.layer.4.attention.self.key.fc_scaling_factor', 'encoder.layer.4.attention.self.key.bias_integer', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight_integer', 'encoder.layer.4.attention.self.value.fc_scaling_factor', 'encoder.layer.4.attention.self.value.bias_integer', 'encoder.layer.4.attention.self.query_activation.x_min', 'encoder.layer.4.attention.self.query_activation.x_max', 'encoder.layer.4.attention.self.query_activation.act_scaling_factor', 'encoder.layer.4.attention.self.key_activation.x_min', 'encoder.layer.4.attention.self.key_activation.x_max', 'encoder.layer.4.attention.self.key_activation.act_scaling_factor', 'encoder.layer.4.attention.self.value_activation.x_min', 'encoder.layer.4.attention.self.value_activation.x_max', 'encoder.layer.4.attention.self.value_activation.act_scaling_factor', 'encoder.layer.4.attention.self.output_activation.x_min', 'encoder.layer.4.attention.self.output_activation.x_max', 'encoder.layer.4.attention.self.output_activation.act_scaling_factor', 'encoder.layer.4.attention.self.softmax.act.x_min', 'encoder.layer.4.attention.self.softmax.act.x_max', 'encoder.layer.4.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight_integer', 'encoder.layer.4.attention.output.dense.fc_scaling_factor', 'encoder.layer.4.attention.output.dense.bias_integer', 'encoder.layer.4.attention.output.ln_input_act.x_min', 'encoder.layer.4.attention.output.ln_input_act.x_max', 'encoder.layer.4.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.shift', 'encoder.layer.4.attention.output.LayerNorm.activation.x_min', 'encoder.layer.4.attention.output.LayerNorm.activation.x_max', 'encoder.layer.4.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.4.attention.output.output_activation.x_min', 'encoder.layer.4.attention.output.output_activation.x_max', 'encoder.layer.4.attention.output.output_activation.act_scaling_factor', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight_integer', 'encoder.layer.4.intermediate.dense.fc_scaling_factor', 'encoder.layer.4.intermediate.dense.bias_integer', 'encoder.layer.4.intermediate.output_activation.x_min', 'encoder.layer.4.intermediate.output_activation.x_max', 'encoder.layer.4.intermediate.output_activation.act_scaling_factor', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight_integer', 'encoder.layer.4.output.dense.fc_scaling_factor', 'encoder.layer.4.output.dense.bias_integer', 'encoder.layer.4.output.ln_input_act.x_min', 'encoder.layer.4.output.ln_input_act.x_max', 'encoder.layer.4.output.ln_input_act.act_scaling_factor', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.shift', 'encoder.layer.4.output.LayerNorm.activation.x_min', 'encoder.layer.4.output.LayerNorm.activation.x_max', 'encoder.layer.4.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.4.output.output_activation.x_min', 'encoder.layer.4.output.output_activation.x_max', 'encoder.layer.4.output.output_activation.act_scaling_factor', 'encoder.layer.4.pre_intermediate_act.x_min', 'encoder.layer.4.pre_intermediate_act.x_max', 'encoder.layer.4.pre_intermediate_act.act_scaling_factor', 'encoder.layer.4.pre_output_act.x_min', 'encoder.layer.4.pre_output_act.x_max', 'encoder.layer.4.pre_output_act.act_scaling_factor', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight_integer', 'encoder.layer.5.attention.self.query.fc_scaling_factor', 'encoder.layer.5.attention.self.query.bias_integer', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight_integer', 'encoder.layer.5.attention.self.key.fc_scaling_factor', 'encoder.layer.5.attention.self.key.bias_integer', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight_integer', 'encoder.layer.5.attention.self.value.fc_scaling_factor', 'encoder.layer.5.attention.self.value.bias_integer', 'encoder.layer.5.attention.self.query_activation.x_min', 'encoder.layer.5.attention.self.query_activation.x_max', 'encoder.layer.5.attention.self.query_activation.act_scaling_factor', 'encoder.layer.5.attention.self.key_activation.x_min', 'encoder.layer.5.attention.self.key_activation.x_max', 'encoder.layer.5.attention.self.key_activation.act_scaling_factor', 'encoder.layer.5.attention.self.value_activation.x_min', 'encoder.layer.5.attention.self.value_activation.x_max', 'encoder.layer.5.attention.self.value_activation.act_scaling_factor', 'encoder.layer.5.attention.self.output_activation.x_min', 'encoder.layer.5.attention.self.output_activation.x_max', 'encoder.layer.5.attention.self.output_activation.act_scaling_factor', 'encoder.layer.5.attention.self.softmax.act.x_min', 'encoder.layer.5.attention.self.softmax.act.x_max', 'encoder.layer.5.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight_integer', 'encoder.layer.5.attention.output.dense.fc_scaling_factor', 'encoder.layer.5.attention.output.dense.bias_integer', 'encoder.layer.5.attention.output.ln_input_act.x_min', 'encoder.layer.5.attention.output.ln_input_act.x_max', 'encoder.layer.5.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.shift', 'encoder.layer.5.attention.output.LayerNorm.activation.x_min', 'encoder.layer.5.attention.output.LayerNorm.activation.x_max', 'encoder.layer.5.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.5.attention.output.output_activation.x_min', 'encoder.layer.5.attention.output.output_activation.x_max', 'encoder.layer.5.attention.output.output_activation.act_scaling_factor', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight_integer', 'encoder.layer.5.intermediate.dense.fc_scaling_factor', 'encoder.layer.5.intermediate.dense.bias_integer', 'encoder.layer.5.intermediate.output_activation.x_min', 'encoder.layer.5.intermediate.output_activation.x_max', 'encoder.layer.5.intermediate.output_activation.act_scaling_factor', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight_integer', 'encoder.layer.5.output.dense.fc_scaling_factor', 'encoder.layer.5.output.dense.bias_integer', 'encoder.layer.5.output.ln_input_act.x_min', 'encoder.layer.5.output.ln_input_act.x_max', 'encoder.layer.5.output.ln_input_act.act_scaling_factor', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.shift', 'encoder.layer.5.output.LayerNorm.activation.x_min', 'encoder.layer.5.output.LayerNorm.activation.x_max', 'encoder.layer.5.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.5.output.output_activation.x_min', 'encoder.layer.5.output.output_activation.x_max', 'encoder.layer.5.output.output_activation.act_scaling_factor', 'encoder.layer.5.pre_intermediate_act.x_min', 'encoder.layer.5.pre_intermediate_act.x_max', 'encoder.layer.5.pre_intermediate_act.act_scaling_factor', 'encoder.layer.5.pre_output_act.x_min', 'encoder.layer.5.pre_output_act.x_max', 'encoder.layer.5.pre_output_act.act_scaling_factor', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight_integer', 'encoder.layer.6.attention.self.query.fc_scaling_factor', 'encoder.layer.6.attention.self.query.bias_integer', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight_integer', 'encoder.layer.6.attention.self.key.fc_scaling_factor', 'encoder.layer.6.attention.self.key.bias_integer', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight_integer', 'encoder.layer.6.attention.self.value.fc_scaling_factor', 'encoder.layer.6.attention.self.value.bias_integer', 'encoder.layer.6.attention.self.query_activation.x_min', 'encoder.layer.6.attention.self.query_activation.x_max', 'encoder.layer.6.attention.self.query_activation.act_scaling_factor', 'encoder.layer.6.attention.self.key_activation.x_min', 'encoder.layer.6.attention.self.key_activation.x_max', 'encoder.layer.6.attention.self.key_activation.act_scaling_factor', 'encoder.layer.6.attention.self.value_activation.x_min', 'encoder.layer.6.attention.self.value_activation.x_max', 'encoder.layer.6.attention.self.value_activation.act_scaling_factor', 'encoder.layer.6.attention.self.output_activation.x_min', 'encoder.layer.6.attention.self.output_activation.x_max', 'encoder.layer.6.attention.self.output_activation.act_scaling_factor', 'encoder.layer.6.attention.self.softmax.act.x_min', 'encoder.layer.6.attention.self.softmax.act.x_max', 'encoder.layer.6.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight_integer', 'encoder.layer.6.attention.output.dense.fc_scaling_factor', 'encoder.layer.6.attention.output.dense.bias_integer', 'encoder.layer.6.attention.output.ln_input_act.x_min', 'encoder.layer.6.attention.output.ln_input_act.x_max', 'encoder.layer.6.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.shift', 'encoder.layer.6.attention.output.LayerNorm.activation.x_min', 'encoder.layer.6.attention.output.LayerNorm.activation.x_max', 'encoder.layer.6.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.6.attention.output.output_activation.x_min', 'encoder.layer.6.attention.output.output_activation.x_max', 'encoder.layer.6.attention.output.output_activation.act_scaling_factor', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight_integer', 'encoder.layer.6.intermediate.dense.fc_scaling_factor', 'encoder.layer.6.intermediate.dense.bias_integer', 'encoder.layer.6.intermediate.output_activation.x_min', 'encoder.layer.6.intermediate.output_activation.x_max', 'encoder.layer.6.intermediate.output_activation.act_scaling_factor', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight_integer', 'encoder.layer.6.output.dense.fc_scaling_factor', 'encoder.layer.6.output.dense.bias_integer', 'encoder.layer.6.output.ln_input_act.x_min', 'encoder.layer.6.output.ln_input_act.x_max', 'encoder.layer.6.output.ln_input_act.act_scaling_factor', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.shift', 'encoder.layer.6.output.LayerNorm.activation.x_min', 'encoder.layer.6.output.LayerNorm.activation.x_max', 'encoder.layer.6.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.6.output.output_activation.x_min', 'encoder.layer.6.output.output_activation.x_max', 'encoder.layer.6.output.output_activation.act_scaling_factor', 'encoder.layer.6.pre_intermediate_act.x_min', 'encoder.layer.6.pre_intermediate_act.x_max', 'encoder.layer.6.pre_intermediate_act.act_scaling_factor', 'encoder.layer.6.pre_output_act.x_min', 'encoder.layer.6.pre_output_act.x_max', 'encoder.layer.6.pre_output_act.act_scaling_factor', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight_integer', 'encoder.layer.7.attention.self.query.fc_scaling_factor', 'encoder.layer.7.attention.self.query.bias_integer', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight_integer', 'encoder.layer.7.attention.self.key.fc_scaling_factor', 'encoder.layer.7.attention.self.key.bias_integer', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight_integer', 'encoder.layer.7.attention.self.value.fc_scaling_factor', 'encoder.layer.7.attention.self.value.bias_integer', 'encoder.layer.7.attention.self.query_activation.x_min', 'encoder.layer.7.attention.self.query_activation.x_max', 'encoder.layer.7.attention.self.query_activation.act_scaling_factor', 'encoder.layer.7.attention.self.key_activation.x_min', 'encoder.layer.7.attention.self.key_activation.x_max', 'encoder.layer.7.attention.self.key_activation.act_scaling_factor', 'encoder.layer.7.attention.self.value_activation.x_min', 'encoder.layer.7.attention.self.value_activation.x_max', 'encoder.layer.7.attention.self.value_activation.act_scaling_factor', 'encoder.layer.7.attention.self.output_activation.x_min', 'encoder.layer.7.attention.self.output_activation.x_max', 'encoder.layer.7.attention.self.output_activation.act_scaling_factor', 'encoder.layer.7.attention.self.softmax.act.x_min', 'encoder.layer.7.attention.self.softmax.act.x_max', 'encoder.layer.7.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight_integer', 'encoder.layer.7.attention.output.dense.fc_scaling_factor', 'encoder.layer.7.attention.output.dense.bias_integer', 'encoder.layer.7.attention.output.ln_input_act.x_min', 'encoder.layer.7.attention.output.ln_input_act.x_max', 'encoder.layer.7.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.shift', 'encoder.layer.7.attention.output.LayerNorm.activation.x_min', 'encoder.layer.7.attention.output.LayerNorm.activation.x_max', 'encoder.layer.7.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.7.attention.output.output_activation.x_min', 'encoder.layer.7.attention.output.output_activation.x_max', 'encoder.layer.7.attention.output.output_activation.act_scaling_factor', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight_integer', 'encoder.layer.7.intermediate.dense.fc_scaling_factor', 'encoder.layer.7.intermediate.dense.bias_integer', 'encoder.layer.7.intermediate.output_activation.x_min', 'encoder.layer.7.intermediate.output_activation.x_max', 'encoder.layer.7.intermediate.output_activation.act_scaling_factor', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight_integer', 'encoder.layer.7.output.dense.fc_scaling_factor', 'encoder.layer.7.output.dense.bias_integer', 'encoder.layer.7.output.ln_input_act.x_min', 'encoder.layer.7.output.ln_input_act.x_max', 'encoder.layer.7.output.ln_input_act.act_scaling_factor', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.shift', 'encoder.layer.7.output.LayerNorm.activation.x_min', 'encoder.layer.7.output.LayerNorm.activation.x_max', 'encoder.layer.7.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.7.output.output_activation.x_min', 'encoder.layer.7.output.output_activation.x_max', 'encoder.layer.7.output.output_activation.act_scaling_factor', 'encoder.layer.7.pre_intermediate_act.x_min', 'encoder.layer.7.pre_intermediate_act.x_max', 'encoder.layer.7.pre_intermediate_act.act_scaling_factor', 'encoder.layer.7.pre_output_act.x_min', 'encoder.layer.7.pre_output_act.x_max', 'encoder.layer.7.pre_output_act.act_scaling_factor', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight_integer', 'encoder.layer.8.attention.self.query.fc_scaling_factor', 'encoder.layer.8.attention.self.query.bias_integer', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight_integer', 'encoder.layer.8.attention.self.key.fc_scaling_factor', 'encoder.layer.8.attention.self.key.bias_integer', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight_integer', 'encoder.layer.8.attention.self.value.fc_scaling_factor', 'encoder.layer.8.attention.self.value.bias_integer', 'encoder.layer.8.attention.self.query_activation.x_min', 'encoder.layer.8.attention.self.query_activation.x_max', 'encoder.layer.8.attention.self.query_activation.act_scaling_factor', 'encoder.layer.8.attention.self.key_activation.x_min', 'encoder.layer.8.attention.self.key_activation.x_max', 'encoder.layer.8.attention.self.key_activation.act_scaling_factor', 'encoder.layer.8.attention.self.value_activation.x_min', 'encoder.layer.8.attention.self.value_activation.x_max', 'encoder.layer.8.attention.self.value_activation.act_scaling_factor', 'encoder.layer.8.attention.self.output_activation.x_min', 'encoder.layer.8.attention.self.output_activation.x_max', 'encoder.layer.8.attention.self.output_activation.act_scaling_factor', 'encoder.layer.8.attention.self.softmax.act.x_min', 'encoder.layer.8.attention.self.softmax.act.x_max', 'encoder.layer.8.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight_integer', 'encoder.layer.8.attention.output.dense.fc_scaling_factor', 'encoder.layer.8.attention.output.dense.bias_integer', 'encoder.layer.8.attention.output.ln_input_act.x_min', 'encoder.layer.8.attention.output.ln_input_act.x_max', 'encoder.layer.8.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.shift', 'encoder.layer.8.attention.output.LayerNorm.activation.x_min', 'encoder.layer.8.attention.output.LayerNorm.activation.x_max', 'encoder.layer.8.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.8.attention.output.output_activation.x_min', 'encoder.layer.8.attention.output.output_activation.x_max', 'encoder.layer.8.attention.output.output_activation.act_scaling_factor', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight_integer', 'encoder.layer.8.intermediate.dense.fc_scaling_factor', 'encoder.layer.8.intermediate.dense.bias_integer', 'encoder.layer.8.intermediate.output_activation.x_min', 'encoder.layer.8.intermediate.output_activation.x_max', 'encoder.layer.8.intermediate.output_activation.act_scaling_factor', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight_integer', 'encoder.layer.8.output.dense.fc_scaling_factor', 'encoder.layer.8.output.dense.bias_integer', 'encoder.layer.8.output.ln_input_act.x_min', 'encoder.layer.8.output.ln_input_act.x_max', 'encoder.layer.8.output.ln_input_act.act_scaling_factor', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.shift', 'encoder.layer.8.output.LayerNorm.activation.x_min', 'encoder.layer.8.output.LayerNorm.activation.x_max', 'encoder.layer.8.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.8.output.output_activation.x_min', 'encoder.layer.8.output.output_activation.x_max', 'encoder.layer.8.output.output_activation.act_scaling_factor', 'encoder.layer.8.pre_intermediate_act.x_min', 'encoder.layer.8.pre_intermediate_act.x_max', 'encoder.layer.8.pre_intermediate_act.act_scaling_factor', 'encoder.layer.8.pre_output_act.x_min', 'encoder.layer.8.pre_output_act.x_max', 'encoder.layer.8.pre_output_act.act_scaling_factor', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight_integer', 'encoder.layer.9.attention.self.query.fc_scaling_factor', 'encoder.layer.9.attention.self.query.bias_integer', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight_integer', 'encoder.layer.9.attention.self.key.fc_scaling_factor', 'encoder.layer.9.attention.self.key.bias_integer', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight_integer', 'encoder.layer.9.attention.self.value.fc_scaling_factor', 'encoder.layer.9.attention.self.value.bias_integer', 'encoder.layer.9.attention.self.query_activation.x_min', 'encoder.layer.9.attention.self.query_activation.x_max', 'encoder.layer.9.attention.self.query_activation.act_scaling_factor', 'encoder.layer.9.attention.self.key_activation.x_min', 'encoder.layer.9.attention.self.key_activation.x_max', 'encoder.layer.9.attention.self.key_activation.act_scaling_factor', 'encoder.layer.9.attention.self.value_activation.x_min', 'encoder.layer.9.attention.self.value_activation.x_max', 'encoder.layer.9.attention.self.value_activation.act_scaling_factor', 'encoder.layer.9.attention.self.output_activation.x_min', 'encoder.layer.9.attention.self.output_activation.x_max', 'encoder.layer.9.attention.self.output_activation.act_scaling_factor', 'encoder.layer.9.attention.self.softmax.act.x_min', 'encoder.layer.9.attention.self.softmax.act.x_max', 'encoder.layer.9.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight_integer', 'encoder.layer.9.attention.output.dense.fc_scaling_factor', 'encoder.layer.9.attention.output.dense.bias_integer', 'encoder.layer.9.attention.output.ln_input_act.x_min', 'encoder.layer.9.attention.output.ln_input_act.x_max', 'encoder.layer.9.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.shift', 'encoder.layer.9.attention.output.LayerNorm.activation.x_min', 'encoder.layer.9.attention.output.LayerNorm.activation.x_max', 'encoder.layer.9.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.9.attention.output.output_activation.x_min', 'encoder.layer.9.attention.output.output_activation.x_max', 'encoder.layer.9.attention.output.output_activation.act_scaling_factor', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight_integer', 'encoder.layer.9.intermediate.dense.fc_scaling_factor', 'encoder.layer.9.intermediate.dense.bias_integer', 'encoder.layer.9.intermediate.output_activation.x_min', 'encoder.layer.9.intermediate.output_activation.x_max', 'encoder.layer.9.intermediate.output_activation.act_scaling_factor', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight_integer', 'encoder.layer.9.output.dense.fc_scaling_factor', 'encoder.layer.9.output.dense.bias_integer', 'encoder.layer.9.output.ln_input_act.x_min', 'encoder.layer.9.output.ln_input_act.x_max', 'encoder.layer.9.output.ln_input_act.act_scaling_factor', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.shift', 'encoder.layer.9.output.LayerNorm.activation.x_min', 'encoder.layer.9.output.LayerNorm.activation.x_max', 'encoder.layer.9.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.9.output.output_activation.x_min', 'encoder.layer.9.output.output_activation.x_max', 'encoder.layer.9.output.output_activation.act_scaling_factor', 'encoder.layer.9.pre_intermediate_act.x_min', 'encoder.layer.9.pre_intermediate_act.x_max', 'encoder.layer.9.pre_intermediate_act.act_scaling_factor', 'encoder.layer.9.pre_output_act.x_min', 'encoder.layer.9.pre_output_act.x_max', 'encoder.layer.9.pre_output_act.act_scaling_factor', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight_integer', 'encoder.layer.10.attention.self.query.fc_scaling_factor', 'encoder.layer.10.attention.self.query.bias_integer', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight_integer', 'encoder.layer.10.attention.self.key.fc_scaling_factor', 'encoder.layer.10.attention.self.key.bias_integer', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight_integer', 'encoder.layer.10.attention.self.value.fc_scaling_factor', 'encoder.layer.10.attention.self.value.bias_integer', 'encoder.layer.10.attention.self.query_activation.x_min', 'encoder.layer.10.attention.self.query_activation.x_max', 'encoder.layer.10.attention.self.query_activation.act_scaling_factor', 'encoder.layer.10.attention.self.key_activation.x_min', 'encoder.layer.10.attention.self.key_activation.x_max', 'encoder.layer.10.attention.self.key_activation.act_scaling_factor', 'encoder.layer.10.attention.self.value_activation.x_min', 'encoder.layer.10.attention.self.value_activation.x_max', 'encoder.layer.10.attention.self.value_activation.act_scaling_factor', 'encoder.layer.10.attention.self.output_activation.x_min', 'encoder.layer.10.attention.self.output_activation.x_max', 'encoder.layer.10.attention.self.output_activation.act_scaling_factor', 'encoder.layer.10.attention.self.softmax.act.x_min', 'encoder.layer.10.attention.self.softmax.act.x_max', 'encoder.layer.10.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight_integer', 'encoder.layer.10.attention.output.dense.fc_scaling_factor', 'encoder.layer.10.attention.output.dense.bias_integer', 'encoder.layer.10.attention.output.ln_input_act.x_min', 'encoder.layer.10.attention.output.ln_input_act.x_max', 'encoder.layer.10.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.shift', 'encoder.layer.10.attention.output.LayerNorm.activation.x_min', 'encoder.layer.10.attention.output.LayerNorm.activation.x_max', 'encoder.layer.10.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.10.attention.output.output_activation.x_min', 'encoder.layer.10.attention.output.output_activation.x_max', 'encoder.layer.10.attention.output.output_activation.act_scaling_factor', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight_integer', 'encoder.layer.10.intermediate.dense.fc_scaling_factor', 'encoder.layer.10.intermediate.dense.bias_integer', 'encoder.layer.10.intermediate.output_activation.x_min', 'encoder.layer.10.intermediate.output_activation.x_max', 'encoder.layer.10.intermediate.output_activation.act_scaling_factor', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight_integer', 'encoder.layer.10.output.dense.fc_scaling_factor', 'encoder.layer.10.output.dense.bias_integer', 'encoder.layer.10.output.ln_input_act.x_min', 'encoder.layer.10.output.ln_input_act.x_max', 'encoder.layer.10.output.ln_input_act.act_scaling_factor', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.shift', 'encoder.layer.10.output.LayerNorm.activation.x_min', 'encoder.layer.10.output.LayerNorm.activation.x_max', 'encoder.layer.10.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.10.output.output_activation.x_min', 'encoder.layer.10.output.output_activation.x_max', 'encoder.layer.10.output.output_activation.act_scaling_factor', 'encoder.layer.10.pre_intermediate_act.x_min', 'encoder.layer.10.pre_intermediate_act.x_max', 'encoder.layer.10.pre_intermediate_act.act_scaling_factor', 'encoder.layer.10.pre_output_act.x_min', 'encoder.layer.10.pre_output_act.x_max', 'encoder.layer.10.pre_output_act.act_scaling_factor', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight_integer', 'encoder.layer.11.attention.self.query.fc_scaling_factor', 'encoder.layer.11.attention.self.query.bias_integer', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight_integer', 'encoder.layer.11.attention.self.key.fc_scaling_factor', 'encoder.layer.11.attention.self.key.bias_integer', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight_integer', 'encoder.layer.11.attention.self.value.fc_scaling_factor', 'encoder.layer.11.attention.self.value.bias_integer', 'encoder.layer.11.attention.self.query_activation.x_min', 'encoder.layer.11.attention.self.query_activation.x_max', 'encoder.layer.11.attention.self.query_activation.act_scaling_factor', 'encoder.layer.11.attention.self.key_activation.x_min', 'encoder.layer.11.attention.self.key_activation.x_max', 'encoder.layer.11.attention.self.key_activation.act_scaling_factor', 'encoder.layer.11.attention.self.value_activation.x_min', 'encoder.layer.11.attention.self.value_activation.x_max', 'encoder.layer.11.attention.self.value_activation.act_scaling_factor', 'encoder.layer.11.attention.self.output_activation.x_min', 'encoder.layer.11.attention.self.output_activation.x_max', 'encoder.layer.11.attention.self.output_activation.act_scaling_factor', 'encoder.layer.11.attention.self.softmax.act.x_min', 'encoder.layer.11.attention.self.softmax.act.x_max', 'encoder.layer.11.attention.self.softmax.act.act_scaling_factor', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight_integer', 'encoder.layer.11.attention.output.dense.fc_scaling_factor', 'encoder.layer.11.attention.output.dense.bias_integer', 'encoder.layer.11.attention.output.ln_input_act.x_min', 'encoder.layer.11.attention.output.ln_input_act.x_max', 'encoder.layer.11.attention.output.ln_input_act.act_scaling_factor', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.shift', 'encoder.layer.11.attention.output.LayerNorm.activation.x_min', 'encoder.layer.11.attention.output.LayerNorm.activation.x_max', 'encoder.layer.11.attention.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.11.attention.output.output_activation.x_min', 'encoder.layer.11.attention.output.output_activation.x_max', 'encoder.layer.11.attention.output.output_activation.act_scaling_factor', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight_integer', 'encoder.layer.11.intermediate.dense.fc_scaling_factor', 'encoder.layer.11.intermediate.dense.bias_integer', 'encoder.layer.11.intermediate.output_activation.x_min', 'encoder.layer.11.intermediate.output_activation.x_max', 'encoder.layer.11.intermediate.output_activation.act_scaling_factor', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight_integer', 'encoder.layer.11.output.dense.fc_scaling_factor', 'encoder.layer.11.output.dense.bias_integer', 'encoder.layer.11.output.ln_input_act.x_min', 'encoder.layer.11.output.ln_input_act.x_max', 'encoder.layer.11.output.ln_input_act.act_scaling_factor', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.shift', 'encoder.layer.11.output.LayerNorm.activation.x_min', 'encoder.layer.11.output.LayerNorm.activation.x_max', 'encoder.layer.11.output.LayerNorm.activation.act_scaling_factor', 'encoder.layer.11.output.output_activation.x_min', 'encoder.layer.11.output.output_activation.x_max', 'encoder.layer.11.output.output_activation.act_scaling_factor', 'encoder.layer.11.pre_intermediate_act.x_min', 'encoder.layer.11.pre_intermediate_act.x_max', 'encoder.layer.11.pre_intermediate_act.act_scaling_factor', 'encoder.layer.11.pre_output_act.x_min', 'encoder.layer.11.pre_output_act.x_max', 'encoder.layer.11.pre_output_act.act_scaling_factor', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc4b550598aa4c7ebc994a85f35b4bac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411325.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42b4007c5ec24dac9b2778dd2a374b96","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qeUr_WRvPLKi"},"source":["# Chuan bi data\n","le = LabelEncoder()\n","le.fit(y_train)\n","# encoding du lieu\n","train_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True, max_length=40)\n","dev_encodings = tokenizer(X_dev.to_list(), truncation=True, padding=True, max_length=40)\n","test_encodings = tokenizer(X_test.to_list(), truncation=True, padding=True, max_length=40)\n","\n","y_train_encoding = le.transform(y_train)\n","y_dev_encoding = le.transform(y_dev)\n","y_test_encoding = le.transform(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFlfUckcPSXU"},"source":["# Chuan bi data\n","\n","train_dataset = BuildDataset(train_encodings, y_train_encoding)\n","dev_dataset = BuildDataset(dev_encodings, y_dev_encoding)\n","test_dataset = BuildDataset(test_encodings, y_test_encoding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIb9mHEPPSaK"},"source":["# Chuan bi mo hinh\n","\n","training_args = TrainingArguments(\n","    output_dir='./results_xlmr',          \n","    num_train_epochs=5,              \n","    per_device_train_batch_size=32,  \n","    per_device_eval_batch_size=32,   \n","    warmup_steps=500,                \n","    weight_decay=0.01,\n","    no_cuda=False\n",")\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    eval_dataset=dev_dataset             \n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"CFq2l5xIPXH5","executionInfo":{"status":"ok","timestamp":1619282987570,"user_tz":-420,"elapsed":814001,"user":{"displayName":"Vĩ Trần Tuấn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjc8eSDsubZaR8W3AcsFrZjBWP1jmcrbcsXAz_4GQ=s64","userId":"12285368666031482492"}},"outputId":"7dc900ce-2656-4ed1-ab2b-0119a8ac9dc0"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [870/870 12:42, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.630400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=870, training_loss=1.3775563207165948, metrics={'train_runtime': 763.6383, 'train_samples_per_second': 1.139, 'total_flos': 889872971275200.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 971083776, 'init_mem_gpu_alloc_delta': 1068132864, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 12505088, 'train_mem_gpu_alloc_delta': 1616796160, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 1022579712})"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"KIqWnYWwPXKb","executionInfo":{"status":"ok","timestamp":1619282991988,"user_tz":-420,"elapsed":818409,"user":{"displayName":"Vĩ Trần Tuấn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjc8eSDsubZaR8W3AcsFrZjBWP1jmcrbcsXAz_4GQ=s64","userId":"12285368666031482492"}},"outputId":"6665891b-12cc-431a-bace-18e416bacba8"},"source":["# Du doan \n","y_pred_classify = trainer.predict(test_dataset)\n","\n","y_pred_xlmr = np.argmax(y_pred_classify.predictions, axis=-1)\n","np.save(\"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis/y_pred_news.npy\",y_pred_xlmr)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [22/22 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"zsh1SZcdPXMw","executionInfo":{"status":"ok","timestamp":1619283408402,"user_tz":-420,"elapsed":789,"user":{"displayName":"Vĩ Trần Tuấn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjc8eSDsubZaR8W3AcsFrZjBWP1jmcrbcsXAz_4GQ=s64","userId":"12285368666031482492"}},"outputId":"e286c28a-de6e-458e-a8a1-5cb36bfce3b4","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Danh gia mo hinh\n","y_true = y_test_encoding\n","np.save(\"/content/drive/MyDrive/NLP-DS/Thực hành 1 - Sentiment analysis/y_true.npy\",y_true)\n","cf = confusion_matrix(y_true, y_pred_xlmr)\n","print(cf)\n","\n","evaluation = f1_score(y_true, y_pred_xlmr, average='micro')\n","\n","print(\"F1 - micro: \" + str(evaluation))\n","\n","evaluation = f1_score(y_true, y_pred_xlmr, average='macro')\n","print(\"F1 - macro: \" + str(evaluation))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[  8  19   1   1   6   5   0]\n"," [  6  68  30   6  16   5   1]\n"," [  1  14 134   5  25  12   2]\n"," [  0   6   6  27   2   5   0]\n"," [  1  17  26   1  67  13   4]\n"," [  1  10  28   4  13  60   0]\n"," [  0   4  11   1  11   1   9]]\n","F1 - micro: 0.5382395382395382\n","F1 - macro: 0.48475428190855857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAloPjgEPe6o"},"source":["# Ve ma tran nham lan\n","df_cm = pd.DataFrame(cf, index = np.unique(y_train),\n","                  columns = np.unique(y_train))\n","\n","sn.heatmap(df_cm, annot=True, cmap=\"Greys\",fmt='g', cbar=True, annot_kws={\"size\": 10})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_50-MF1Pe9g"},"source":[""],"execution_count":null,"outputs":[]}]}